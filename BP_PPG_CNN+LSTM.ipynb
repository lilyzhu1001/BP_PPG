{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BP_PPG_CNN+LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNXa/Xn8I82rpuZ8kzItDvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/BP_PPG/blob/master/BP_PPG_CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWP-_pXlUKmp",
        "colab_type": "text"
      },
      "source": [
        "#1.Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mOoV1yuUKlh",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains an simple PPG DNN by using labeled PPG data from Afib_Data_Clean notebook;\n",
        "The loaded data is 30s segemented PPG signals with 125Hz sampling rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfCfr60kSTDU",
        "colab_type": "text"
      },
      "source": [
        "#2.Setup Environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvqxVijHSFk2",
        "colab_type": "code",
        "outputId": "13bfff84-0fa8-4760-82c1-9c61a9c1881c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import tensorflow_datasets as tfds\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import sklearn.metrics\n",
        "import itertools\n",
        "import io\n",
        "import pickle\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8y478FMSLVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this cell to log device placement info\n",
        "tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Qo9PRdSOdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBpW2rfESO-0",
        "colab_type": "code",
        "outputId": "0f91bada-2b78-4562-f6c2-1da2b79e16c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oFD2ZNOoGMsP"
      },
      "source": [
        "#3.Data Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KpK35SW3GMsU"
      },
      "source": [
        "# 3.1 Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwdd-WA-Xtb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = \"D:/WFDB/matched/BP/Cleaned Data/train/train_BP_data*\"\n",
        "train_data_fn = glob.glob(train_data_dir)\n",
        "train_label_dir = \"D:/WFDB/matched/BP/Cleaned Data/train/train_BP_label*\"\n",
        "train_label_fn = glob.glob(train_label_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJapqLn-Uejo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_fn,train_label_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdtZjE5eUnLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label = tf.data.TFRecordDataset(filenames = [train_file_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVBoNZ3iWhbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = tf.data.TFRecordDataset(filenames = [val_file_list])\n",
        "val_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4vdK0boWjSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = tf.data.TFRecordDataset(filenames = [test_file_list])\n",
        "test_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4u32j5uJGMs8"
      },
      "source": [
        "## 3.2 Extract, Transform and Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bG4_EtxRGMs8"
      },
      "source": [
        "###3.2.1 Parallelize Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0Mo73K8GMs9",
        "colab": {}
      },
      "source": [
        "#use interleave if more than one file are used\n",
        "train = tf.data.Dataset.from_tensor_slices((train_dataset,train_labels)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GaQyR9mhGMs_",
        "colab": {}
      },
      "source": [
        "validation = tf.data.Dataset.from_tensor_slices((val_dataset,val_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ss2nwlA3GMtB"
      },
      "source": [
        "### 3.2.2 Parallelize Transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "988c8f16-7016-45c0-a876-1b741a94dd64",
        "id": "wt9paii8GMtB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#don't need to run this cell, just as a placeholder\n",
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "#dataset = dataset.map(function, num_parallel_calls = cores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0PxkcHUtGMtD"
      },
      "source": [
        "### 3.2.3 Parallelize Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0eNX0PYsGMtE",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_dataset = train.cache()\n",
        "train_dataset = train_dataset.shuffle(len(list(train))).repeat().batch(batch_size,drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = validation.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiF9-uDTI-h",
        "colab_type": "text"
      },
      "source": [
        "#4.Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeF1mUEJTN60",
        "colab_type": "text"
      },
      "source": [
        "##4.1 CNN + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gH902sEMO7T",
        "colab_type": "code",
        "outputId": "366c0b1a-6e34-4614-973e-9d9b0d3aa1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "BatchNormalization._USE_V2_BEHAVIOR = False\n",
        "#create CNN layers\n",
        "cnn = tf.keras.Sequential([\n",
        "    #1st Conv1D\n",
        "    tf.keras.layers.Conv1D(8, 1, strides=1, \n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #2nd Conv1D\n",
        "    tf.keras.layers.Conv1D(16, 3, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #3rd Conv1D\n",
        "    tf.keras.layers.Conv1D(32, 3, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #4th Conv1D\n",
        "    tf.keras.layers.Conv1D(64, 3, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2,strides=2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #5th Conv1D\n",
        "    tf.keras.layers.Conv1D(16, 1, strides=1,\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #Full connection layer\n",
        "    tf.keras.layers.Flatten()\n",
        "])\n",
        "\n",
        "#combine with LSTM\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.TimeDistributed(cnn,input_shape=(10,750,1)),                   \n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "        tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 10, 720)           9776      \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 64)            192768    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 32)                10368     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 212,978\n",
            "Trainable params: 212,706\n",
            "Non-trainable params: 272\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV4AOP5AXh5P",
        "colab_type": "text"
      },
      "source": [
        "##4.2 Define callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_1LxToVXqBO",
        "colab_type": "text"
      },
      "source": [
        "###4.2.1 Learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqkfWOvWXlfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decay(epoch):\n",
        "  if epoch < 50:\n",
        "    return 1e-3\n",
        "  elif epoch >= 50 and epoch < 200:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyV2EoQtXtV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: schedule a learning rate incline iteration\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8quc5CXwa5",
        "colab_type": "text"
      },
      "source": [
        "###4.2.2 Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7h_p1YnXz1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: tensorboard\n",
        "log_dir=r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Blood pressure\\BP data\\logs\\fit\\\\\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") +\"CNN+LSTM\"\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcdMgfv1YClx",
        "colab_type": "text"
      },
      "source": [
        "###4.2.4 Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSqNrDZ_YKFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#callback: checkpoint\n",
        "filepath = r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Blood pressure\\BP data\\models\\CNN+LSTM-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ril_S4TVJS",
        "colab_type": "text"
      },
      "source": [
        "##4.3 Train the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYor7DsTcXT",
        "colab_type": "text"
      },
      "source": [
        "### 4.3.1 Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eqeVT1uTeOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clear history if necessary\n",
        "tf.keras.backend.clear_session()\n",
        "#strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) ##to overwrite NCCL cross device communication as this is running in Windows\n",
        "#with strategy.scope():\n",
        "\n",
        "model = model\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='mse', \n",
        "              metrics=['mae'])\n",
        "\n",
        "callbacks_list = [tensorboard_callback, checkpoint, lr_schedule]\n",
        "\n",
        "#start training\n",
        "model.fit(train_dataset,\n",
        "          epochs=300,\n",
        "          steps_per_epoch = len(list(train))/batch_size,\n",
        "          verbose=1,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps = len(list(validation))/batch_size,\n",
        "          callbacks=callbacks_list\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUv7BhOTiua",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Save Model for future evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ricCF8i5Tnoz",
        "colab_type": "code",
        "outputId": "d44f2063-2e78-4a59-caf8-9a582c87ce2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Afib\\Afib_ECG data\")\n",
        "model.save('Deep_PPG_CNN_041120.h5')\n",
        "print(\"Save model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfnasVq2Tqjg",
        "colab_type": "text"
      },
      "source": [
        "# 5.Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a8QzHAVT1bz",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZyzAHekTsy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(r\"C:\\Users\\57lzhang.US04WW4008\\Desktop\\Blood pressure\\BP data\\models\")\n",
        "model = tf.keras.models.load_model('CNN+LSTM-285-10.2110.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aMp1YpLTw7C",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScA5IlA-G84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bp_estimate=model.predict(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGR81k40A44c",
        "colab_type": "code",
        "outputId": "88b3d002-688d-4841-d7c0-2a133f525a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "sys_mae = mean_absolute_error(test_labels[:,0], bp_estimate[:,0])\n",
        "dia_mae = mean_absolute_error(test_labels[:,1], bp_estimate[:,1])\n",
        "print(\"Systolic MAE in test dataset:\", round(sys_mae,1))\n",
        "print(\"Diastolic MAE in test dataset:\", round(dia_mae,1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Systolic MAE in test dataset: 11.2\n",
            "Diastolic MAE in test dataset: 6.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}